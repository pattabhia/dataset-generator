# ğŸ“¦ LLaMAFactory Dataset Generator

---

## Features

### **1. Multi-Domain Support**

Select any domain using:

```bash
--domain haiintel_core
--domain expense
--domain <your-custom-domain>
```

### **2. YAML Configuration**

Everything (company, agent name, products, regions, doc types, currencies) is
controlled through:

```
config.yaml
```

No need to edit Python files for domain updates.

---

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- pip (Python package manager)
- jq (optional, for JSON formatting)

---

## How to Run

### **1. Install dependencies**

```bash
# Install all dependencies including dev tools
pip install -r requirements.txt

# Or install only core dependencies
pip install pyyaml
```

Alternatively, use the Makefile:

```bash
make install
```

### **2. Prepare your `config.yaml`**

Example:

```yaml
domains:
  - id: expense
    company_name: "<Company Name>"
    agent_name: "<Agent Name>"
    chat_agent_name: "HAI Expense Agent"
    domain_name: "Expense Management"
    kb_label: "HaiIntel Expense Knowledge Base"
    primary_products: ["HAIExpenseLens", "HAIIndexer"]
    primary_roles: ["CFO", "Finance Controller"]
    primary_regions: ["Global", "UAE", "India"]
    entity_types: ["Invoice", "Receipt", "ExpensePolicy", "Vendor"]
    expense_doc_types: ["Invoice", "Bill", "Receipt"]
    currencies: ["INR", "USD", "AED"]
```

---

### **3. Run the CLI**

**Option A: Direct Python command**

```bash
python -m src.cli --config config.yaml --domain expense --out-dir ./training-jsons
```

**Option B: Using Makefile**

```bash
# Generate for a specific domain
make generate DOMAIN=expense

# Generate for all domains in config.yaml
make generate-all
```

### Output:

The generator creates JSON files with training examples and statistics:

```
training-jsons/
â”œâ”€ intro-training.json                           # Introduction and greeting examples
â”œâ”€ intro-training_stats.json                     # Statistics for intro dataset
â”œâ”€ operator-training.json                        # Operator logic examples
â”œâ”€ operator-training_stats.json
â”œâ”€ rag_context_training.json                     # RAG context handling
â”œâ”€ rag_context_training_stats.json
â”œâ”€ entity-classification-training.json           # Entity type classification
â”œâ”€ entity-classification-training_stats.json
â”œâ”€ safety_guardrails_training.json               # Safety and guardrails
â”œâ”€ safety_guardrails_training_stats.json
â”œâ”€ hard_negatives_hallucinations.json            # Hard negative examples
â”œâ”€ hard_negatives_hallucinations_stats.json
â”œâ”€ company_kb_training.json                      # Company knowledge base Q&A
â”œâ”€ company_kb_training_stats.json
â”œâ”€ company_kb_no_hallucinations_training.json    # KB with anti-hallucination
â”œâ”€ company_kb_no_hallucinations_training_stats.json
â”œâ”€ business_integration_training.json            # Business integration scenarios
â”œâ”€ business_integration_training_stats.json
â””â”€ expense_documents_training.json               # Domain-specific: Expense docs
    â””â”€ expense_documents_training_stats.json
```

---

## ğŸ› ï¸ Makefile Targets

The project includes a comprehensive Makefile for common tasks:

| Target              | Description                                                |
| ------------------- | ---------------------------------------------------------- |
| `make install`      | Create virtual environment and install dependencies        |
| `make generate`     | Generate dataset for a specific domain (use `DOMAIN=name`) |
| `make generate-all` | Generate datasets for all domains in config.yaml           |
| `make shell`        | Enter the virtual environment shell                        |
| `make format`       | Format all JSON files using jq                             |
| `make clean-venv`   | Remove virtual environment                                 |
| `make clean-output` | Remove generated training files                            |
| `make clean`        | Clean everything (venv + output)                           |

**Examples:**

```bash
# Generate for expense domain
make generate DOMAIN=expense

# Generate for all domains
make generate-all

# Clean and regenerate
make clean && make generate-all

# Format JSON output
make format
```

---

## ğŸ§  Philosophy

This project applies the **SOLID principles**:

- **Single Responsibility** â†’ Each section has its own builder module
- **Open/Closed** â†’ Add a new section by adding a new file in `sections/`
- **Liskov Substitution** â†’ All builders behave via `SectionBuilder`
- **Interface Segregation** â†’ Minimal interface
- **Dependency Inversion** â†’ High-level generator depends on factory, not concrete classes

It's also:

- **DRY** â†’ Common utilities in `utils.py`
- **Extensible** â†’ Easily add new JSON schemas & builders
- **Testable** â†’ Builders are pure functions returning a list of examples
- **Quality-First** â†’ Automatic deduplication, validation, and statistics generation

---

## ğŸ” Key Features

### **Entity Classification with Rule-Based Classifier**

The entity classification module uses a keyword-based classifier to generate meaningful training examples:

- **Automatic Classification**: Entities are classified based on keywords (e.g., "Invoice", "Person", "Vendor")
- **Domain-Specific**: Supports multiple entity types per domain (configured in `config.yaml`)
- **Extensible**: Easy to add new entity types and keywords in `src/utils.py:classify_entity_name()`

**Example Output:**

```json
{
  "system": "You are HAIIndexer classification module. Classify the given string into one or more entity types.",
  "instruction": "What type of entity is Global Invoice for CFO 001?",
  "input": "Global Invoice for CFO 001",
  "output": "This entity belongs to the following types: Person, Invoice",
  "metadata": {
    "section": "entity_classification",
    "classified_as": ["Person", "Invoice"],
    "possible_labels": ["Person", "CostCenter", "ExpensePolicy", ...]
  }
}
```

### **Dataset Quality Assurance**

- **Validation**: All examples are validated before saving
- **Deduplication**: Duplicate examples are automatically removed
- **Statistics**: Each dataset includes a companion `*_stats.json` file with:
  - Total examples count
  - Estimated token count
  - Section breakdown

---

## ğŸ“ Project Structure

```
dataset-generator/
â”œâ”€â”€ config.yaml              # Multi-domain configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Makefile                 # Build automation
â”œâ”€â”€ README.md                # This file
â””â”€â”€ src/
    â”œâ”€â”€ cli.py              # Command-line interface
    â”œâ”€â”€ domain_config.py    # Domain configuration data class
    â”œâ”€â”€ factory.py          # Section builder factory
    â”œâ”€â”€ generator.py        # Main dataset generator
    â”œâ”€â”€ utils.py            # Shared utilities and entity classifier
    â””â”€â”€ sections/           # Section builders (one per training type)
        â”œâ”€â”€ base.py
        â”œâ”€â”€ intro.py
        â”œâ”€â”€ operator.py
        â”œâ”€â”€ entity_classification.py
        â”œâ”€â”€ rag_context.py
        â”œâ”€â”€ safety.py
        â””â”€â”€ ...
```

---

## ğŸš€ Adding a New Domain

1. **Edit `config.yaml`** and add a new domain entry:

```yaml
domains:
  - id: my_new_domain
    company_name: "MyCompany"
    agent_name: "MyAgent"
    domain_name: "My Domain"
    entity_types: ["TypeA", "TypeB"]
    # ... other configuration
```

2. **Extend entity classifier** (optional):

If you have new entity types, add keyword patterns in `src/utils.py:classify_entity_name()`

3. **Generate datasets**:

```bash
make generate DOMAIN=my_new_domain
```

---

## ğŸ§ª Development

### **Code Quality Tools**

The project supports modern Python development tools:

```bash
# Install dev dependencies
pip install -r requirements.txt

# Format code
black src/

# Type checking
mypy src/

# Linting
ruff src/

# Run tests (if implemented)
pytest
```

---
